{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4df55e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using base: /Users/Phillip/Downloads/musicnet 2\n",
      "Train tracks: 320\n",
      "Keeping train: 40\n",
      "Top 15 train IDs: [2310, 2234, 2305, 2238, 2196, 2247, 2232, 2207, 2230, 2240, 2292, 2228, 2214, 2224, 2302]\n",
      "Reduced dataset at: /Users/Phillip/Downloads/musicnet 2_small\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "import os, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "SRC_ROOT = Path(r\"/Users/Phillip/Downloads/musicnet 2\") #path to the musicnet dataset\n",
    "DST_ROOT = SRC_ROOT.parent / (SRC_ROOT.name + \"_small\")\n",
    "\n",
    "# Keep fixed test IDs if they exist locally\n",
    "TEST_KEEP_IDS = {1759, 1819, 2106, 2191, 2298, 2303, 2382, 2416, 2556, 2628}\n",
    "\n",
    "# M1-friendly size (adjust if you want)\n",
    "TRAIN_KEEP_N = 40          # <- start here (40); \n",
    "MIN_EVENTS = 300\n",
    "COPY_INSTEAD_OF_MOVE = True   # safer; set False if you want to free disk\n",
    "\n",
    "def ensure_structure(root: Path) -> dict[str, Path]:\n",
    "    root = root.expanduser().resolve()\n",
    "    expected = [\"train_data\", \"train_labels\", \"test_data\", \"test_labels\"]\n",
    "    if all((root / e).exists() for e in expected):\n",
    "        base = root\n",
    "    elif (root / \"musicnet\").exists() and all(((root / \"musicnet\") / e).exists() for e in expected):\n",
    "        base = root / \"musicnet\"\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Can't find {expected} under {root}\")\n",
    "    return {\n",
    "        \"base\": base,\n",
    "        \"train_wav\": base / \"train_data\",\n",
    "        \"train_csv\": base / \"train_labels\",\n",
    "        \"test_wav\":  base / \"test_data\",\n",
    "        \"test_csv\":  base / \"test_labels\",\n",
    "    }\n",
    "\n",
    "def wav_id(p: Path):\n",
    "    try: return int(p.stem)\n",
    "    except: return None\n",
    "\n",
    "def label_stats(csv_path: Path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if \"start_time\" not in df.columns or \"end_time\" not in df.columns:\n",
    "        return (0.0, len(df), 0.0)\n",
    "    t0 = df[\"start_time\"].min()\n",
    "    t1 = df[\"end_time\"].max()\n",
    "    dur = float(t1 - t0) if pd.notnull(t1) else 0.0\n",
    "    events = len(df)\n",
    "    dens = events / dur if dur > 0 else 0.0\n",
    "    return (dur, events, dens)\n",
    "\n",
    "def build_table(wav_dir: Path, csv_dir: Path) -> pd.DataFrame:\n",
    "    rows = []\n",
    "    for wav in sorted(wav_dir.glob(\"*.wav\")):\n",
    "        tid = wav_id(wav)\n",
    "        if tid is None: \n",
    "            continue\n",
    "        csv = csv_dir / f\"{wav.stem}.csv\"\n",
    "        if not csv.exists():\n",
    "            continue\n",
    "        size_mb = os.path.getsize(wav) / 1e6\n",
    "        dur, events, dens = label_stats(csv)\n",
    "        rows.append(dict(id=tid, wav=wav, csv=csv, size_mb=size_mb, dur_units=dur, events=events, density=dens))\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "def transfer(src: Path, dst: Path, copy: bool):\n",
    "    dst.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if copy: shutil.copy2(src, dst)\n",
    "    else: shutil.move(str(src), str(dst))\n",
    "\n",
    "dirs = ensure_structure(SRC_ROOT)\n",
    "print(\"Using base:\", dirs[\"base\"])\n",
    "\n",
    "train_tbl = build_table(dirs[\"train_wav\"], dirs[\"train_csv\"])\n",
    "print(\"Train tracks:\", len(train_tbl))\n",
    "\n",
    "tbl = train_tbl[train_tbl[\"events\"] >= MIN_EVENTS].copy()\n",
    "\n",
    "# Score: high density + event count, penalize extreme duration\n",
    "tbl[\"score\"] = np.log1p(tbl[\"density\"]) + 0.03*np.log1p(tbl[\"events\"]) - 0.15*np.log1p(tbl[\"dur_units\"])\n",
    "tbl = tbl.sort_values(\"score\", ascending=False)\n",
    "\n",
    "keep_train = tbl[\"id\"].head(TRAIN_KEEP_N).astype(int).tolist()\n",
    "\n",
    "print(\"Keeping train:\", len(keep_train))\n",
    "print(\"Top 15 train IDs:\", keep_train[:15])\n",
    "\n",
    "for sub in [\"train_data\", \"train_labels\", \"test_data\", \"test_labels\"]:\n",
    "    (DST_ROOT / sub).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Train\n",
    "for tid in keep_train:\n",
    "    wav = dirs[\"train_wav\"] / f\"{tid}.wav\"\n",
    "    csv = dirs[\"train_csv\"] / f\"{tid}.csv\"\n",
    "    if wav.exists() and csv.exists():\n",
    "        transfer(wav, DST_ROOT/\"train_data\"/wav.name, COPY_INSTEAD_OF_MOVE)\n",
    "        transfer(csv, DST_ROOT/\"train_labels\"/csv.name, COPY_INSTEAD_OF_MOVE)\n",
    "\n",
    "# Test (only if present)\n",
    "missing_test = []\n",
    "for tid in sorted(TEST_KEEP_IDS):\n",
    "    wav = dirs[\"test_wav\"] / f\"{tid}.wav\"\n",
    "    csv = dirs[\"test_csv\"] / f\"{tid}.csv\"\n",
    "    if wav.exists() and csv.exists():\n",
    "        transfer(wav, DST_ROOT/\"test_data\"/wav.name, COPY_INSTEAD_OF_MOVE)\n",
    "        transfer(csv, DST_ROOT/\"test_labels\"/csv.name, COPY_INSTEAD_OF_MOVE)\n",
    "    else:\n",
    "        missing_test.append(tid)\n",
    "\n",
    "print(\"Reduced dataset at:\", DST_ROOT)\n",
    "if missing_test:\n",
    "    print(\"Note: missing some requested test IDs locally:\", missing_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.11.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
